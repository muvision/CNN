{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_DPTxoJF_lV",
    "tags": []
   },
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yYUJZtAE7pmq",
    "outputId": "d660cbf8-e3f1-4aa6-bd1d-2cd593667585"
   },
   "outputs": [],
   "source": [
    "!pip install opendatasets\n",
    "!pip install pandas\n",
    "import tensorflow as tf\n",
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOANaXd38oyz"
   },
   "outputs": [],
   "source": [
    "# Download the dataset from the Kaggle API\n",
    "# od.download('https://www.kaggle.com/datasets/sagyamthapa/handwritten-math-symbols', force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWp7X9UPJgHW",
    "tags": []
   },
   "source": [
    "## Preprocess the Colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "yLPtqNmMHSAb",
    "outputId": "fe1b72db-b0ce-4e0b-a6a4-f9f069707617"
   },
   "outputs": [],
   "source": [
    "sample_img_path = os.path.join(os.curdir, 'handwritten-math-symbols', 'dataset', '0', '0CdBlhLw.png')\n",
    "img = np.asarray(Image.open(sample_img_path))\n",
    "imgplot = plt.imshow(img)\n",
    "print(repr(img))\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEMHxizrKRLu"
   },
   "outputs": [],
   "source": [
    "# Convert from CMYK to Gray scale\n",
    "data_dir = os.path.join(os.curdir, 'handwritten-math-symbols', 'dataset')\n",
    "\n",
    "for image_class in os.listdir(data_dir):\n",
    "  if image_class.startswith('.'):\n",
    "    continue\n",
    "  for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "    try:\n",
    "      image_path = os.path.join(data_dir, image_class, image)\n",
    "      image = cv.imread(image_path)\n",
    "      grayImage = cv.cvtColor(image, cv.COLOR_RGBA2RGB)\n",
    "      cv.imwrite(image_path, grayImage)\n",
    "    except:\n",
    "      continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "GxVjwaXZWqMS",
    "outputId": "5cfb6f73-a1f4-4f54-8cbb-0029235daf53"
   },
   "outputs": [],
   "source": [
    "img = np.asarray(Image.open(sample_img_path))\n",
    "imgplot = plt.imshow(img)\n",
    "print(repr(img))\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJbNBW8LFXA3",
    "outputId": "0d630fca-45b5-45ba-be0a-75cb84b50491"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "image_size = (32,32)\n",
    "data_set = tf.keras.utils.image_dataset_from_directory(data_dir, batch_size = batch_size, image_size = image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZzzNJdvGHtnF",
    "outputId": "741b4fa0-6013-4833-df0b-0caa27a89fb3"
   },
   "outputs": [],
   "source": [
    "print(repr(img))\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4yTIBDOJvMk",
    "tags": []
   },
   "source": [
    "## Preprocess data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F12eza_fcJa7",
    "outputId": "dfe5d9fd-3c82-46b6-b8f0-1aa74e852285"
   },
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "imread(sample_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkqzgjG7IEGP"
   },
   "outputs": [],
   "source": [
    "# Normalize images\n",
    "data_set = data_set.map(lambda x,y: (x/255, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOVFdFmSMmoC"
   },
   "outputs": [],
   "source": [
    "input_shape=(32,32,3)\n",
    "\n",
    "train_size = int(len(data_set)* .7)\n",
    "val_size = int(len(data_set)*.2)+1\n",
    "test_size = int(len(data_set)*.1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbfMgfxcM3JB"
   },
   "outputs": [],
   "source": [
    "train = data_set.take(train_size)\n",
    "val = data_set.skip(train_size).take(val_size)\n",
    "test = data_set.skip(train_size + val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uAWBF3bxBTi",
    "tags": []
   },
   "source": [
    "## Create Custom Model using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkc5ozRCxMmh"
   },
   "outputs": [],
   "source": [
    "tf_model = models.Sequential(name='Custom_Model')\n",
    "\n",
    "# Convolutional base\n",
    "tf_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "tf_model.add(layers.MaxPooling2D((2, 2)))\n",
    "tf_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "tf_model.add(layers.MaxPooling2D((2, 2)))\n",
    "tf_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Dense layers\n",
    "tf_model.add(layers.Flatten())\n",
    "tf_model.add(layers.Dense(64, activation='relu'))\n",
    "tf_model.add(layers.Dense(19))\n",
    "tf_model.summary()\n",
    "\n",
    "# The summary shows that the convolutional base has a (4, 4, 64) output, which\n",
    "#   is flattened into a (1024) shaped vector, and then sent through two Dense\n",
    "#   layers\n",
    "\n",
    "tf_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "tf_history = tf_model.fit(train, epochs=10,\n",
    "                    validation_data=val)\n",
    "\n",
    "tf_model.save(os.path.join(os.curdir, 'models', 'tf_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ci4F0BLbA62T"
   },
   "outputs": [],
   "source": [
    "plt.plot(tf_history.history['accuracy'], label='accuracy')\n",
    "plt.plot(tf_history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = tf_model.evaluate(test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jLHDig8hGrS",
    "tags": []
   },
   "source": [
    "## Create Model using Resnet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43sdMFwOpo-n",
    "outputId": "a503d55e-3f23-447a-8a1d-eb0b95c8a9dc"
   },
   "outputs": [],
   "source": [
    "img_height = 32\n",
    "img_width = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir, validation_split=0.2, subset=\"training\", seed=123,\n",
    "    label_mode='categorical', image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1BtElvMp_TH",
    "outputId": "41a4645e-2406-48e1-c751-c26860e0cb36"
   },
   "outputs": [],
   "source": [
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir, validation_split=0.2, subset=\"validation\", seed=123, \n",
    "    label_mode='categorical', image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVZLejYThHdq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "resnet_model = Sequential(name='Resnet_Model')\n",
    "\n",
    "resnet_pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
    "\n",
    "                   input_shape=input_shape,\n",
    "\n",
    "                   pooling='avg',classes=19,\n",
    "\n",
    "                   weights='imagenet')\n",
    "\n",
    "for each_layer in resnet_pretrained_model.layers:\n",
    "\n",
    "        each_layer.trainable=False\n",
    "\n",
    "resnet_model.add(resnet_pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXyHjfHxiWmS"
   },
   "outputs": [],
   "source": [
    "resnet_model.add(Flatten())\n",
    "\n",
    "resnet_model.add(Dense(512, activation='relu'))\n",
    "resnet_model.add(Dense(19, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ocwg282iXPl",
    "outputId": "1ebd728c-b508-4f3a-e3ab-f348046e2a94"
   },
   "outputs": [],
   "source": [
    "resnet_model.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "history = resnet_model.fit(train_ds, validation_data=validation_ds, epochs=epochs)\n",
    "resnet_model.save(os.path.join(os.curdir, 'models', 'resnet_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meRo2PWxiY_u"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "epochs_range= range(epochs)\n",
    "\n",
    "plt.plot( epochs_range, history.history['accuracy'], label=\"Training Accuracy\")\n",
    "\n",
    "plt.plot(epochs_range, history.history['val_accuracy'], label=\"Validation Accuracy\")\n",
    "\n",
    "plt.axis(ymin=0.4,ymax=1)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "\n",
    "plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SiBOhhbziax_"
   },
   "outputs": [],
   "source": [
    "#plotter_lib.show()\n",
    "\n",
    "plt.savefig('output-plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05exxZ78FTOH",
    "tags": []
   },
   "source": [
    "## Create Model using VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YoNT2YT6FX8n"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tEPnt0EwFdji"
   },
   "outputs": [],
   "source": [
    "vgg19_model = Sequential(name='VGG19_Model')\n",
    "\n",
    "vgg19_pretrained_model= tf.keras.applications.VGG19(include_top=False,\n",
    "\n",
    "                   input_shape=input_shape,\n",
    "\n",
    "                   pooling='avg',classes=19,\n",
    "\n",
    "                   weights='imagenet')\n",
    "\n",
    "for each_layer in vgg19_pretrained_model.layers:\n",
    "        each_layer.trainable=False\n",
    "\n",
    "vgg19_model.add(vgg19_pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Amd07fJYKPv2"
   },
   "outputs": [],
   "source": [
    "vgg19_model.add(Flatten())\n",
    "\n",
    "vgg19_model.add(Dense(512, activation='relu'))\n",
    "\n",
    "vgg19_model.add(Dense(19, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sywhMHGQKXf9"
   },
   "outputs": [],
   "source": [
    "vgg19_model.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "epochs = 8\n",
    "try:\n",
    "  history = vgg19_model.fit(train_ds, validation_data=validation_ds, epochs=epochs)\n",
    "except Exception as e: print(e)\n",
    "\n",
    "vgg19_model.save(os.path.join(os.curdir, 'models', 'vgg19_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_yb_-_GUCna"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "epochs_range= range(epochs)\n",
    "\n",
    "plt.plot( epochs_range, history.history['accuracy'], label=\"Training Accuracy\")\n",
    "\n",
    "plt.plot(epochs_range, history.history['val_accuracy'], label=\"Validation Accuracy\")\n",
    "\n",
    "plt.axis(ymin=0.4,ymax=1)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "\n",
    "plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5fjuSxMCglJ",
    "tags": []
   },
   "source": [
    "## Create Model using MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHkMzA0qCyHJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zknr1QcpCjbm"
   },
   "outputs": [],
   "source": [
    "# Mobilenet requires a minimum 96x96 image size\n",
    "mobilenet_input_shape = (96, 96, 3)\n",
    "mobilenet_image_size = (96, 96)\n",
    "mobilenet_data_set = tf.keras.utils.image_dataset_from_directory(data_dir, batch_size = batch_size, image_size = mobilenet_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir, validation_split=0.2, subset=\"training\", seed=123,\n",
    "    label_mode='categorical', image_size=mobilenet_image_size,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "mobilenet_validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir, validation_split=0.2, subset=\"validation\", seed=123, \n",
    "    label_mode='categorical', image_size=mobilenet_image_size,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mobilenet_model = Sequential(name='MobileNet_Model')\n",
    "mobilenet_pretrained_model = tf.keras.applications.MobileNetV2(include_top=False,\n",
    "\n",
    "                   input_shape=mobilenet_input_shape,\n",
    "\n",
    "                   pooling='avg',classes=19,\n",
    "\n",
    "                   weights='imagenet')\n",
    "\n",
    "for each_layer in mobilenet_pretrained_model.layers:\n",
    "        each_layer.trainable=False\n",
    "\n",
    "mobilenet_model.add(mobilenet_pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model.add(Flatten())\n",
    "\n",
    "mobilenet_model.add(Dense(512, activation='relu'))\n",
    "\n",
    "mobilenet_model.add(Dense(19, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "epochs = 8\n",
    "try:\n",
    "  history = mobilenet_model.fit(mobilenet_train_ds, validation_data=mobilenet_validation_ds, epochs=epochs)\n",
    "except Exception as e: print(e)\n",
    "mobilenet_model.save(os.path.join(os.curdir, 'models', 'mobilenet_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "epochs_range= range(epochs)\n",
    "\n",
    "plt.plot(epochs_range, history.history['accuracy'], label=\"Training Accuracy\")\n",
    "\n",
    "plt.plot(epochs_range, history.history['val_accuracy'], label=\"Validation Accuracy\")\n",
    "\n",
    "plt.axis(ymin=0.4,ymax=1)\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "\n",
    "plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can ensemble our 4 models to improve our performance.\n",
    "# We will use the weighted average method to ensemble the models.\n",
    "def weighted_init(shape= (1,1,1), weights = [1,1,1], dtype = tf.float32):\n",
    "    return tf.constant(np.array(weights).reshape(shape), dtype = dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedAverage(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(WeightedAverage, self).__init__()\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.W = self.add_weight(\n",
    "            shape=(1,1,len(input_shape)),\n",
    "            initializer=weighted_init,\n",
    "            dtype=tf.float32,\n",
    "            trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        inputs = [tf.expand_dims(i, -1) for i in inputs]\n",
    "        inputs = layers.Concatenate(axis=-1)(inputs)\n",
    "        weights = tf.nn.softmax(self.W, axis=-1)\n",
    "        \n",
    "        return tf.reduce_mean(weights*inputs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained models from file system\n",
    "tf_model_path = os.path.join(os.curdir, 'models', 'tf_model.h5')\n",
    "resnet_model_path = os.path.join(os.curdir, 'models', 'resnet_model.h5')\n",
    "vgg19_model_path = os.path.join(os.curdir, 'models', 'vgg19_model.h5')\n",
    "mobilenet_model_path = os.path.join(os.curdir, 'models', 'mobilenet_model.h5')\n",
    "\n",
    "models = [models.load_model(tf_model_path),\n",
    "          models.load_model(resnet_model_path),\n",
    "          models.load_model(vgg19_model_path)]\n",
    "          # models.load_model(mobilenet_model_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "input_shape=(32, 32, 3)\n",
    "input = layers.Input(shape=input_shape, name='input')\n",
    "\n",
    "outputs = [model(input) for model in models]\n",
    "\n",
    "x = WeightedAverage()(outputs)\n",
    "\n",
    "output = layers.Dense(19, activation='softmax')(x)\n",
    "\n",
    "weighted_avg_model = tf.keras.Model(input, output, name= 'Weighted_Average_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree Diagram of weighted average model\n",
    "tf.keras.utils.plot_model(weighted_avg_model)\n",
    "plt.axis('off')\n",
    "weighted_avg_model_img_path = os.path.join(os.curdir, 'model.png')\n",
    "weighted_avg_model_img = np.asarray(Image.open(weighted_avg_model_img_path))\n",
    "imgplot = plt.imshow(weighted_avg_model_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "aWp7X9UPJgHW",
    "8uAWBF3bxBTi",
    "v5fjuSxMCglJ"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
